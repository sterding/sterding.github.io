---
layout: post
title: Running R on cluster in a job_array way
date: '2010-10-28T19:09:00.000-04:00'
author: Xianjun
tags:
- cluster
- bash
- job_array
- R
modified_time: '2010-10-28T19:33:54.830-04:00'
blogger_id: tag:blogger.com,1999:blog-12445049.post-9134659812152844061
blogger_orig_url: http://onetipperday.blogspot.com/2010/10/simple-job-array-howto-gridwiki.html
---

<a href="http://wiki.gridengine.info/wiki/index.php/Simple-Job-Array-Howto">Simple-Job-Array-Howto - GridWiki</a>: "Example: R Scripts with Grid Engine Job Arrays<br /><br />All of the above applies to well-behaved, interactive programs. However, sometimes you need to use R to analyze your data. In order to do this, you have to hardcode file names into the R script, because these scripts are not interactive. This is a royal pain. However, there is a solution that makes use of HERE documents in bash. HERE documents also exist in perl, and an online tutorial for them in bash is at http://www.tldp.org/LDP/abs/html/here-docs.html. The short of it is that a HERE document can represent a skeleton document at the end of a shell script. Let’s concoct an example. You have 100 data files, labeled data.1 to data.10. Each file contains a single column of numbers, and you want to do some calculation for each of them, using R. Let’s use a HERE document:<br /><blockquote><pre>#!/bin/sh<br />#$ -t 1-10<br />WORKDIR=/Users/jl566/testing<br />INFILE=$WORKDIR/data.$SGE_TASK_ID<br />OUTFILE=$WORKDIR/data.$SGE_TASK_ID.out<br /># See comment below about paths to R<br />PATHTOR=/common/bin<br />if [ -e $OUTFILE ]<br />then<br />rm -f $OUTFILE<br />fi<br /># Below, the phrase "EOF" marks the beginning and end of the HERE document.<br /># Basically, what’s going on is that we’re running R, and suppressing all of<br /># it’s output to STDOUT, and then redirecting whatever’s between the EOF words<br /># as an R script, and using variable substitution to act on the desired files.<br />$PATHTOR/R --quiet --no-save > /dev/null << EOF<br />x<-read.table("$INFILE")<br />write(mean(x\$V1),"$OUTFILE")<br />EOF<br /></pre></blockquote><br />So now you can use the cluster to analyze your data – just write the R script within the HERE document, and go from there. As I’ve only just figured this out, some caveats are necessary. If anyone experiments and figures out something neat, let me know. Be aware of the following:<br /><br />1. In my limited experience, indenting is important for HERE documents. In particular, it seems that the beginning and end (i.e. both lines containing the term EOF in the above example), must be aligned with the left-hand edge of the buffer (i.e. not indented at all). So, if you use a HERE document in a conditional or control statement, be mindful of this.<br />2. In the mean command, I escaped the dollar sign with a backslash. In my limited experiments, both mean(x\$V1) and mean(x$V1) seem to work. However, escaping the dollar sign for the read.table command prevents the variable substitution from occurring in the shell, causing R to fail, because the input file named $INFILE cannot be found. In other words, escaping in that context causes the HERE doc to pass $INFILE as a string literal to R, rather than the value stored in the shell variable.<br />3. This is more useful than just array jobs on an SGE system. If you know bash well enough, you can write a shell script that takes a load of arguments, and processes them with a HERE document. This solves a major limitation with R scripts themselves. You can do the same in perl, too, on your workstation, but you must use a shell language on the cluster.<br /><br />- Sent using Google Toolbar"