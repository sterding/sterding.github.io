---
layout: post
title: Tips and Tools you may need for working on BIG data
date: '2015-05-08T12:40:00.000-04:00'
author: Xianjun Dong
tags:
- Illustrator
- wget
- big data
- parallel
- axel
- R
modified_time: '2015-05-08T12:40:34.743-04:00'
blogger_id: tag:blogger.com,1999:blog-12445049.post-8994621354415160802
blogger_orig_url: http://onetipperday.blogspot.com/2015/05/tips-and-tools-you-may-need-for-working.html
---

Nowadays everyone is talking about big data. As a genomic scientist, I could feel hungry of a collection of tools more specialized for the mediate-to-big data we deal everyday.<br /><br />Here are some tips I found useful when getting, processing or visualizing large data set:<br /><br /><b style="background-color: white;">1. How to download data faster than wget?</b><br /><b style="background-color: yellow;"><br /></b>We can use wget to download the data to local disk. If it's large, we can download with other faster alternative, such as <span style="background-color: yellow;"><span style="font-family: Courier New, Courier, monospace;"><b>axel, aria2</b></span></span>.<br /><br />http://www.cyberciti.biz/tips/download-accelerator-for-linux-command-line-tools.html<br /><br /><b style="background-color: white;">2. Process the data in parallel with hidden option in GNU commands</b><br /><br /><ul><li>If you have many many files to process, and they are independent, you can process them in a parallel manner. GNU has a command called <span style="background-color: yellow; font-family: Courier New, Courier, monospace;"><b>parallel</b></span>. Lindenbaum Pierre wrote a nice notebook&nbsp;for "<a href="http://figshare.com/articles/GNU_parallel_for_Bioinformatics_my_notebook/822138">GNU Parallel in Bioinformatics</a>", worthy to read.&nbsp;</li><li>Many commonly used commands also have a hidden option to run in a parallel way. For example, GNU sort command has&nbsp;<a href="https://www.gnu.org/software/coreutils/manual/html_node/sort-invocation.html"><span class="s1">--parallel</span><span class="s2">=</span></a><span class="s3"><a href="https://www.gnu.org/software/coreutils/manual/html_node/sort-invocation.html">N</a> to set it with multiple cores.&nbsp;</span></li><li><span class="s3">You can set -F when doing grep -f on a large seed file. People also suggest to set<a href="http://stackoverflow.com/questions/9066609/fastest-possible-grep">&nbsp;</a></span><a href="http://stackoverflow.com/questions/9066609/fastest-possible-grep"><span class="pln" style="background-color: #eeeeee; border: 0px; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; font-size: 13px; margin: 0px; padding: 0px; white-space: inherit;">export LC_ALL</span><span class="pun" style="background-color: #eeeeee; border: 0px; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; font-size: 13px; margin: 0px; padding: 0px; white-space: inherit;">=</span><span class="pln" style="background-color: #eeeeee; border: 0px; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; font-size: 13px; margin: 0px; padding: 0px; white-space: inherit;">C</span> </a>line to get X2 speed.</li></ul><br /><b><span style="background-color: white;">3. In R, there are several must-have tips for large data, e.g. </span><span style="background-color: yellow; font-family: Courier New, Courier, monospace;">data.table</span></b><br /><ul><li>If using <span style="font-family: Courier New, Courier, monospace;">read.table()</span>, set <span style="font-family: Courier New, Courier, monospace;">stringsAsFactors = F </span>and colClass. See <a href="http://simplystatistics.tumblr.com/post/11142408176/r-workshop-reading-in-large-data-frames">the example here</a>.&nbsp;</li><li>use <span style="font-family: Courier New, Courier, monospace;">fread()</span>, not <span style="font-family: Courier New, Courier, monospace;">read.table</span>(). Some <a href="http://davetang.org/muse/2013/09/03/handling-big-data-in-r/">more details here</a>. But so far, <span style="font-family: Courier New, Courier, monospace;">fread</span>() does not support reading *.gz file directly. Use&nbsp;<span style="background-color: rgba(0, 0, 0, 0.0392157); color: #333333; font-family: Courier New, Courier, monospace; font-size: 11.8999996185303px; line-height: 19.0400009155273px;">fread('zcat file.gz')</span></li><li>use <span style="font-family: Courier New, Courier, monospace;">data.table</span>, rather data.frame. Learn the difference <a href="https://campus.datacamp.com/courses/data-table-data-manipulation-r-tutorial">online here</a>.</li><li>There is a nice View for how to process data in parallel in R:&nbsp;<a href="http://cran.r-project.org/web/views/HighPerformanceComputing.html">http://cran.r-project.org/web/views/HighPerformanceComputing.html</a>, but I have not followed them practically. Hopefully there will be some easy tutorials there, or I become less procrastinated to learn some of them ... At least I can start with <span style="font-family: Courier New, Courier, monospace;"><a href="http://cran.r-project.org/web/packages/foreach/vignettes/foreach.pdf" style="background-color: yellow;"><b>foreach</b></a>()</span></li><li>http://stackoverflow.com/questions/1727772/quickly-reading-very-large-tables-as-dataframes-in-r</li></ul><b style="background-color: white;">4. How to open scatter plot with too many points in Illustrator?</b><br /><b style="background-color: yellow;"><br /></b>This is really a problem for me as we usually have a figure with &gt;30k dots (i.e. each dot is a gene). Even though they are highly overlapping each other, opening it in Illustrator is extremely slow. Here is a tip:&nbsp;http://tex.stackexchange.com/questions/39974/problem-with-a-very-heavy-eps-image-scatter-plot-too-heavy-as-eps<br />From that, probably a better idea is to "compress" the data before plotting it, such as merge the overlapped ones if they overlapped some %.<br />or this one:<br />http://stackoverflow.com/questions/18852395/writing-png-plots-into-a-pdf-file-in-r<br />or this one:<br />http://stackoverflow.com/questions/7714677/r-scatterplot-with-too-many-points<br /><br />Still working on the post...<br /><br />